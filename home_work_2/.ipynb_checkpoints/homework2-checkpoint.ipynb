{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21140</th>\n",
       "      <td>23637f0c47938444</td>\n",
       "      <td>== Aaron z. zucker == \\n\\n Hello TeaDrinker, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108634</th>\n",
       "      <td>b542af93fa822009</td>\n",
       "      <td>Edit: first example was incorrect and biased. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97124</th>\n",
       "      <td>a210b5a4746d84d8</td>\n",
       "      <td>Photo needed \\n We need a photo to add on this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87590</th>\n",
       "      <td>92250f4934be7470</td>\n",
       "      <td>\" \\n\\n Ludwigs2, the debate about the word 'ps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27836</th>\n",
       "      <td>2e5726f3782b8b1c</td>\n",
       "      <td>Please refrain from adding nonsense to Wikiped...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92425</th>\n",
       "      <td>9a178f95fcf12009</td>\n",
       "      <td>== Plenty of people do support you == \\n\\n Ple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90972</th>\n",
       "      <td>97ae42a89ff43783</td>\n",
       "      <td>\" \\n\\n == I take it as a source of pride == \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>028e5db74363f713</td>\n",
       "      <td>Currently he and his colleagues from his newsp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109277</th>\n",
       "      <td>b64b868646fa42ac</td>\n",
       "      <td>== Provisional Government == \\n\\n * Hello, sir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149555</th>\n",
       "      <td>f9fc4524802d685e</td>\n",
       "      <td>strap on cock because i am messed up in the he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text\n",
       "21140   23637f0c47938444  == Aaron z. zucker == \\n\\n Hello TeaDrinker, y...\n",
       "108634  b542af93fa822009  Edit: first example was incorrect and biased. ...\n",
       "97124   a210b5a4746d84d8  Photo needed \\n We need a photo to add on this...\n",
       "87590   92250f4934be7470  \" \\n\\n Ludwigs2, the debate about the word 'ps...\n",
       "27836   2e5726f3782b8b1c  Please refrain from adding nonsense to Wikiped...\n",
       "92425   9a178f95fcf12009  == Plenty of people do support you == \\n\\n Ple...\n",
       "90972   97ae42a89ff43783  \" \\n\\n == I take it as a source of pride == \\n...\n",
       "1517    028e5db74363f713  Currently he and his colleagues from his newsp...\n",
       "109277  b64b868646fa42ac  == Provisional Government == \\n\\n * Hello, sir...\n",
       "149555  f9fc4524802d685e  strap on cock because i am messed up in the he..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most common word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(text):\n",
    "    \n",
    "    result = re.findall(r\"[a-z]+'?[a-z]+\", text.lower())\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train['comment_text'].apply(get_words)\n",
    "\n",
    "test_text = test['comment_text'].apply(get_words)\n",
    "\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = list()\n",
    "for line in all_text:\n",
    "    total.extend(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 919035), ('to', 539236), ('of', 410839)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = Counter(total)\n",
    "count.most_common(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какое слово встречается чаще всего в объединенном train и test датасете? - **'the'** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Увеличение параметра C в Logistic regression увеличивает или уменьшает степень регуляризации?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличение параметра C в Logistic regression увеличивает или уменьшает степень регуляризации?\n",
    "\n",
    "**C** – обратный коэффициент регуляризации (тот самый C в sklearn-реализации LogisticRegression)\n",
    "\n",
    "Ответ: **Уменьшает**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train_text.apply(lambda text: ' '.join(text))\n",
    "\n",
    "test_text = test_text.apply(lambda text: ' '.join(text))\n",
    "\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer или CountVectorizer\n",
    "word_vectorizer = TfidfVectorizer() \n",
    "\n",
    "word_vectorizer.fit(all_text)\n",
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "test_word_features = word_vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.9724238498388088\n",
      "CV score for class severe_toxic is 0.9833079735989355\n",
      "CV score for class obscene is 0.9843418455895124\n",
      "CV score for class threat is 0.98638587067384\n",
      "CV score for class insult is 0.9763643664586121\n",
      "CV score for class identity_hate is 0.973462305990869\n",
      "Total score is 0.9793810353584296\n"
     ]
    }
   ],
   "source": [
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "class_c = [4, 2, 3, 4, 3, 3]\n",
    "\n",
    "scores= []\n",
    "\n",
    "for class_name, C in zip(class_names, class_c):\n",
    "    \n",
    "    classifier = LogisticRegression(C=C,random_state=7) \n",
    "\n",
    "    train_target = train[class_name]\n",
    "\n",
    "    cv_score = np.mean(cross_val_score(classifier, train_word_features, train_target, scoring='roc_auc'))\n",
    "\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "    scores.append(cv_score)\n",
    "\n",
    "print('Total score is {}'.format(np.mean(scores)))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Total score is  **0.9793810353584296** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create submission for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['clean_comment'] = train_text\n",
    "test['clean_comment'] = test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add some features to train and test\n",
    "train['count_sent'] = train[\"comment_text\"].apply(lambda x: len(re.findall(\"\\n\",str(x)))+1)\n",
    "train['count_words'] = train[\"clean_comment\"].apply(lambda x: len(str(x).split()))\n",
    "train['count_unique_words'] = train[\"clean_comment\"].apply(lambda x: len(set(str(x).split())))\n",
    "train['count_letters'] = train[\"clean_comment\"].apply(lambda x: len(str(x)))\n",
    "train[\"count_punctuations\"] = train[\"comment_text\"].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "train[\"count_words_upper\"] = train[\"comment_text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "train[\"count_words_title\"] = train[\"comment_text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "\n",
    "\n",
    "test['count_sent'] = test[\"comment_text\"].apply(lambda x: len(re.findall(\"\\n\",str(x)))+1)\n",
    "test['count_words'] = test[\"clean_comment\"].apply(lambda x: len(str(x).split()))\n",
    "test['count_unique_words'] = test[\"clean_comment\"].apply(lambda x: len(set(str(x).split())))\n",
    "test['count_letters'] = test[\"clean_comment\"].apply(lambda x: len(str(x)))\n",
    "test[\"count_punctuations\"] = test[\"comment_text\"].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "test[\"count_words_upper\"] = test[\"comment_text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "test[\"count_words_title\"] = test[\"comment_text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = train[train.columns[-7:]]\n",
    "features_test = test[train.columns[-7:]]\n",
    "\n",
    "word_vectorizer = TfidfVectorizer() \n",
    "\n",
    "word_vectorizer.fit(all_text)\n",
    "\n",
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "test_word_features = word_vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_train shape: (159571, 7)\n",
      "Train word features shape: (159571, 286201)\n"
     ]
    }
   ],
   "source": [
    "features_train = csr_matrix(features_train)\n",
    "features_test = csr_matrix(features_test)\n",
    "\n",
    "print('Features_train shape: {}'.format(features_train.shape))\n",
    "print('Train word features shape: {}'.format(train_word_features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = hstack([train_word_features, features_train])\n",
    "\n",
    "x_test = hstack([test_word_features, features_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict({'id': test['id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "class_c = [4, 2, 3, 4, 3, 3]\n",
    "\n",
    "for class_name, C in zip(class_names, class_c):\n",
    "    \n",
    "    y_train = train[class_name]\n",
    "    \n",
    "    classifier = LogisticRegression(C=C,random_state=7)\n",
    "      \n",
    "    classifier.fit(x_train, y_train)\n",
    "    \n",
    "    submission[class_name] = classifier.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.069878</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.035369</td>\n",
       "      <td>1.423250e-09</td>\n",
       "      <td>0.030425</td>\n",
       "      <td>0.000717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.225610</td>\n",
       "      <td>0.045461</td>\n",
       "      <td>0.097415</td>\n",
       "      <td>2.221269e-02</td>\n",
       "      <td>0.094416</td>\n",
       "      <td>0.032334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.204816</td>\n",
       "      <td>0.066885</td>\n",
       "      <td>0.108946</td>\n",
       "      <td>4.843859e-02</td>\n",
       "      <td>0.107200</td>\n",
       "      <td>0.022976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.160552</td>\n",
       "      <td>0.009108</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>1.007349e-04</td>\n",
       "      <td>0.061581</td>\n",
       "      <td>0.014589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.248664</td>\n",
       "      <td>0.062445</td>\n",
       "      <td>0.104271</td>\n",
       "      <td>8.405659e-02</td>\n",
       "      <td>0.102166</td>\n",
       "      <td>0.083637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene        threat    insult  \\\n",
       "0  00001cee341fdb12  0.069878      0.000326  0.035369  1.423250e-09  0.030425   \n",
       "1  0000247867823ef7  0.225610      0.045461  0.097415  2.221269e-02  0.094416   \n",
       "2  00013b17ad220c46  0.204816      0.066885  0.108946  4.843859e-02  0.107200   \n",
       "3  00017563c3f7919a  0.160552      0.009108  0.065000  1.007349e-04  0.061581   \n",
       "4  00017695ad8997eb  0.248664      0.062445  0.104271  8.405659e-02  0.102166   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.000717  \n",
       "1       0.032334  \n",
       "2       0.022976  \n",
       "3       0.014589  \n",
       "4       0.083637  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
